{
  
    
        "post0": {
            "title": "A Basic Neural Network: Differentiate Hand-Written Digits",
            "content": "Key Objectives: . Building a neural network that differentiates two hand-written digits 3 and 8. | Comparing the results of this Neural Network (NN) to that of a Logistic Regression (LR) model. | . Requirements: . &#39;Kudzu&#39; : A neural network library that was designed during our course by Univ.AI. | MNIST Database | . If MNIST is not installed, use the command !pip install mnist given below. It can be run both from the command line and Jupyter Notebook. . !pip install mnist . Collecting mnist Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB) Requirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.6.12/x64/lib/python3.6/site-packages (from mnist) (1.19.2) Installing collected packages: mnist Successfully installed mnist-0.2.2 . Importing necessary libraries . %load_ext autoreload %autoreload 2 %matplotlib inline import matplotlib.pyplot as plt import numpy as np import pandas as pd . Preparing the Data . import mnist . train_images = mnist.train_images() train_labels = mnist.train_labels() . train_images.shape, train_labels.shape . ((60000, 28, 28), (60000,)) . test_images = mnist.test_images() test_labels = mnist.test_labels() . test_images.shape, test_labels.shape . ((10000, 28, 28), (10000,)) . image_index = 7776 # You may select anything up to 60,000 print(train_labels[image_index]) plt.imshow(train_images[image_index], cmap=&#39;Greys&#39;) . 2 . &lt;matplotlib.image.AxesImage at 0x7f57de1757f0&gt; . Filter data to get 3 and 8 out . train_filter = np.where((train_labels == 3 ) | (train_labels == 8)) test_filter = np.where((test_labels == 3) | (test_labels == 8)) X_train, y_train = train_images[train_filter], train_labels[train_filter] X_test, y_test = test_images[test_filter], test_labels[test_filter] . We normalize the pixel values in the 0 to 1 range . X_train = X_train/255. X_test = X_test/255. . Setup the labels as 1 (when the digit is 3) and 0 (when the digit is 8) . y_train = 1*(y_train==3) y_test = 1*(y_test==3) . X_train.shape, X_test.shape . ((11982, 28, 28), (1984, 28, 28)) . Reshape the input data to create a linear array . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . Importing appropriate functions from &#39;Kudzu&#39; . from kudzu.layer import Sigmoid from kudzu.layer import Relu from kudzu.layer import Affine, Sigmoid from kudzu.model import Model from kudzu.train import Learner from kudzu.optim import GD from kudzu.data import Data, Dataloader, Sampler from kudzu.callbacks import AccCallback from kudzu.callbacks import ClfCallback from kudzu.loss import MSE . Let us create a Config class, to store important parameters. . This class essentially plays the role of a dictionary. . class Config: pass config = Config() config.lr = 0.001 config.num_epochs = 251 config.bs = 50 . Initializing data to the variables . data = Data(X_train, y_train.reshape(-1,1)) sampler = Sampler(data, config.bs, shuffle=True) dl = Dataloader(data, sampler) opt = GD(config.lr) loss = MSE() . training_xdata = X_train testing_xdata = X_test training_ydata = y_train.reshape(-1,1) testing_ydata = y_test.reshape(-1,1) . Running Models with the Training data . Details about the network layers: . A first affine layer has 784 inputs and does 100 affine transforms. These are followed by a Relu | A second affine layer has 100 inputs from the 100 activations of the past layer, and does 100 affine transforms. These are followed by a Relu | A third affine layer has 100 activations and does 2 affine transformations to create an embedding for visualization. There is no non-linearity here. | A final &quot;logistic regression&quot; which has an affine transform from 2 inputs to 1 output, which is squeezed through a sigmoid. | . Help taken from Anshuman&#39;s Notebook. . # layers for the Neural Network layers = [Affine(&quot;first&quot;, 784, 100), Relu(&quot;first&quot;), Affine(&quot;second&quot;, 100, 100), Relu(&quot;second&quot;), Affine(&quot;third&quot;, 100, 2), Affine(&quot;final&quot;, 2, 1), Sigmoid(&quot;final&quot;)] model_nn = Model(layers) # layers for the Logistic Regression layers_lr = [Affine(&quot;logits&quot;, 784, 1), Sigmoid(&quot;sigmoid&quot;)] model_lr = Model(layers_lr) . # suffix _nn stands for Neural Network. learner_nn = Learner(loss, model_nn, opt, config.num_epochs) acc_nn = ClfCallback(learner_nn, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_nn.set_callbacks([acc_nn]) . print(&quot;====== Neural Network ======&quot;) learner_nn.train_loop(dl) . ====== Neural Network ====== Epoch 0, Loss 0.2508 Training Accuracy: 0.5353, Testing Accuracy: 0.5338 Epoch 10, Loss 0.1014 Training Accuracy: 0.9200, Testing Accuracy: 0.9355 Epoch 20, Loss 0.0592 Training Accuracy: 0.9393, Testing Accuracy: 0.9471 Epoch 30, Loss 0.0461 Training Accuracy: 0.9503, Testing Accuracy: 0.9577 Epoch 40, Loss 0.0397 Training Accuracy: 0.9556, Testing Accuracy: 0.9617 Epoch 50, Loss 0.0358 Training Accuracy: 0.9587, Testing Accuracy: 0.9637 Epoch 60, Loss 0.0332 Training Accuracy: 0.9615, Testing Accuracy: 0.9672 Epoch 70, Loss 0.0312 Training Accuracy: 0.9631, Testing Accuracy: 0.9688 Epoch 80, Loss 0.0297 Training Accuracy: 0.9649, Testing Accuracy: 0.9698 Epoch 90, Loss 0.0284 Training Accuracy: 0.9669, Testing Accuracy: 0.9708 Epoch 100, Loss 0.0274 Training Accuracy: 0.9680, Testing Accuracy: 0.9713 Epoch 110, Loss 0.0264 Training Accuracy: 0.9690, Testing Accuracy: 0.9718 Epoch 120, Loss 0.0256 Training Accuracy: 0.9700, Testing Accuracy: 0.9723 Epoch 130, Loss 0.0248 Training Accuracy: 0.9710, Testing Accuracy: 0.9728 Epoch 140, Loss 0.0241 Training Accuracy: 0.9717, Testing Accuracy: 0.9723 Epoch 150, Loss 0.0235 Training Accuracy: 0.9725, Testing Accuracy: 0.9728 Epoch 160, Loss 0.0229 Training Accuracy: 0.9739, Testing Accuracy: 0.9733 Epoch 170, Loss 0.0224 Training Accuracy: 0.9743, Testing Accuracy: 0.9738 Epoch 180, Loss 0.0218 Training Accuracy: 0.9753, Testing Accuracy: 0.9738 Epoch 190, Loss 0.0213 Training Accuracy: 0.9756, Testing Accuracy: 0.9738 Epoch 200, Loss 0.0208 Training Accuracy: 0.9761, Testing Accuracy: 0.9748 Epoch 210, Loss 0.0204 Training Accuracy: 0.9766, Testing Accuracy: 0.9748 Epoch 220, Loss 0.02 Training Accuracy: 0.9770, Testing Accuracy: 0.9748 Epoch 230, Loss 0.0196 Training Accuracy: 0.9779, Testing Accuracy: 0.9753 Epoch 240, Loss 0.0192 Training Accuracy: 0.9783, Testing Accuracy: 0.9758 Epoch 250, Loss 0.0188 Training Accuracy: 0.9787, Testing Accuracy: 0.9758 . 0.00756172655550473 . Logistic Regression based Implementation. . learner_lr = Learner(loss, model_lr, opt, config.num_epochs) acc_lr = ClfCallback(learner_lr, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_lr.set_callbacks([acc_lr]) . print(&quot;====== Logistic Regression ======&quot;) learner_lr.train_loop(dl) . ====== Logistic Regression ====== Epoch 0, Loss 0.2603 Training Accuracy: 0.6203, Testing Accuracy: 0.6195 Epoch 10, Loss 0.1061 Training Accuracy: 0.8957, Testing Accuracy: 0.9078 Epoch 20, Loss 0.0803 Training Accuracy: 0.9234, Testing Accuracy: 0.9375 Epoch 30, Loss 0.0686 Training Accuracy: 0.9344, Testing Accuracy: 0.9516 Epoch 40, Loss 0.0616 Training Accuracy: 0.9400, Testing Accuracy: 0.9546 Epoch 50, Loss 0.0569 Training Accuracy: 0.9451, Testing Accuracy: 0.9587 Epoch 60, Loss 0.0535 Training Accuracy: 0.9479, Testing Accuracy: 0.9582 Epoch 70, Loss 0.0508 Training Accuracy: 0.9501, Testing Accuracy: 0.9597 Epoch 80, Loss 0.0488 Training Accuracy: 0.9521, Testing Accuracy: 0.9612 Epoch 90, Loss 0.0471 Training Accuracy: 0.9534, Testing Accuracy: 0.9622 Epoch 100, Loss 0.0456 Training Accuracy: 0.9548, Testing Accuracy: 0.9637 Epoch 110, Loss 0.0444 Training Accuracy: 0.9558, Testing Accuracy: 0.9647 Epoch 120, Loss 0.0433 Training Accuracy: 0.9565, Testing Accuracy: 0.9657 Epoch 130, Loss 0.0424 Training Accuracy: 0.9572, Testing Accuracy: 0.9657 Epoch 140, Loss 0.0416 Training Accuracy: 0.9578, Testing Accuracy: 0.9662 Epoch 150, Loss 0.0408 Training Accuracy: 0.9581, Testing Accuracy: 0.9667 Epoch 160, Loss 0.0402 Training Accuracy: 0.9585, Testing Accuracy: 0.9667 Epoch 170, Loss 0.0396 Training Accuracy: 0.9594, Testing Accuracy: 0.9672 Epoch 180, Loss 0.039 Training Accuracy: 0.9598, Testing Accuracy: 0.9677 Epoch 190, Loss 0.0385 Training Accuracy: 0.9601, Testing Accuracy: 0.9677 Epoch 200, Loss 0.038 Training Accuracy: 0.9603, Testing Accuracy: 0.9682 Epoch 210, Loss 0.0376 Training Accuracy: 0.9605, Testing Accuracy: 0.9688 Epoch 220, Loss 0.0372 Training Accuracy: 0.9609, Testing Accuracy: 0.9693 Epoch 230, Loss 0.0368 Training Accuracy: 0.9613, Testing Accuracy: 0.9693 Epoch 240, Loss 0.0365 Training Accuracy: 0.9611, Testing Accuracy: 0.9693 Epoch 250, Loss 0.0361 Training Accuracy: 0.9612, Testing Accuracy: 0.9693 . 0.027153358816962726 . Comparing results of NN and LR . plt.figure(figsize=(15,10)) # Neural Network plots plt.plot(acc_nn.accuracies, &#39;r-&#39;, label = &quot;Training Accuracies - NN&quot;) plt.plot(acc_nn.test_accuracies, &#39;g-&#39;, label = &quot;Testing Accuracies - NN&quot;) # Logistic Regression plots plt.plot(acc_lr.accuracies, &#39;k-&#39;, label = &quot;Training Accuracies - LR&quot;) plt.plot(acc_lr.test_accuracies, &#39;b-&#39;, label = &quot;Testing Accuracies - LR&quot;) plt.ylim(0.8, 1) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f57dbcdb2e8&gt; . From the plot, we can observe the following: . Neural Network achieves higher accuracy than the Logistic Regression model. | This apparently, is because of overfitting, i.e. NN captures more noise than data. | Testing accuracy of NN drops below the Training accuracy at higher epochs. This explains the over-fitting on training data. | Logistic Regression gives a reliable accuracy, without the above mentioned problem. | . Moving till the last but one layer (excluding it). . Plotting the outputs of this layer of the NN. . model_new = Model(layers[:-2]) . plot_testing = model_new(testing_xdata) . plt.figure(figsize=(8,7)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()); plt.title(&#39;Outputs&#39;) . Text(0.5, 1.0, &#39;Outputs&#39;) . Plotting probability contours . model_prob = Model(layers[-2:]) . # Adjust the x and y ranges according to the above generated plot. x_range = np.linspace(-4, 1, 100) y_range = np.linspace(-6, 6, 100) x_grid, y_grid = np.meshgrid(x_range, y_range) # x_grid and y_grig are of size 100 X 100 # converting x_grid and y_grid to continuous arrays x_grid_flat = np.ravel(x_grid) y_grid_flat = np.ravel(y_grid) # The last layer of the current model takes two columns as input. Hence transpose of np.vstack() is required. X = np.vstack((x_grid_flat, y_grid_flat)).T # x_grid and y_grid are of size 100 x 100 probability_contour = model_prob(X).reshape(100,100) . plt.figure(figsize=(10,9)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()) contours = plt.contour(x_grid,y_grid,probability_contour) plt.title(&#39;Probability Contours&#39;) plt.clabel(contours, inline = True ); .",
            "url": "https://akshithsriram.github.io/blog/2020/08/11/NeuralNetwork.html",
            "relUrl": "/2020/08/11/NeuralNetwork.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Covid-19 Dashboard: Auto-updated",
            "content": "Welcome! This version of the dashboard updates itself everyday with the latest information. . #collapse from datetime import datetime import pandas as pd import numpy as np # For making web-requests to the website import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl %matplotlib inline from IPython.core.display import display,HTML latest_df = pd.read_csv(&quot;https://api.covid19india.org/csv/latest/state_wise_daily.csv&quot;) latest_df.head() df_1 = latest_df[(latest_df.Status == &quot;Confirmed&quot;)] df_1 = df_1.drop(columns = [&quot;Status&quot;]) df_2 = latest_df[(latest_df.Status == &quot;Deceased&quot;)] df_2 = df_2.drop(columns = [&quot;Status&quot;]) df_1[&quot;Date&quot;] = df_1[&quot;Date&quot;].astype(&#39;datetime64[ns]&#39;) update = latest_df.iloc[-1,0] cases = df_1.TT.sum() new = df_1.iloc[-1,1] deaths = df_2.TT.sum() df_new = df_2.iloc[-1,1] overview = &#39;&#39;&#39; &lt;!-- ####### HTML!! #########--&gt; &lt;h1 style=&quot;color: #5e9ca0; text-align: center;&quot;&gt;India&lt;/h1&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Last update: &lt;strong&gt;{update}&lt;/strong&gt;&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed cases:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{cases} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{new}&lt;/span&gt;)&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed deaths:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{deaths} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{df_new}&lt;/span&gt;)&lt;/p&gt; &#39;&#39;&#39; html = HTML(overview.format(update=update, cases=cases,new=new,deaths=deaths,df_new=df_new)) display(html) . . India . Last update: 30-Sep-20 . Confirmed cases: . 6309634 (+86748) . Confirmed deaths: . 98121 (+1179) . #collapse current_time = datetime.now().time() # time object print(&quot;Last Updated: &quot;, current_time) . . Last Updated: 10:07:35.980393 . #collapse # For ten states n = 10 st = [&quot;TT&quot;, &quot;MH&quot;, &quot;TN&quot;, &quot;DL&quot;, &quot;KA&quot;, &quot;UP&quot;, &quot;BR&quot;, &quot;WB&quot;, &quot;TG&quot;, &quot;AP&quot;] state_name = [&quot;India&quot;, &quot;Maharashta&quot;, &quot;Tamil Nadu&quot;, &quot;Delhi&quot;, &quot;Karnataka&quot;, &quot;Uttar Pradesh&quot;, &quot;Bihar&quot;, &quot;West Bengal&quot;, &quot;Telangana&quot;, &quot;Andhra Pradesh&quot;] fig = plt.figure(figsize = (16,30)) gridspec = fig.add_gridspec(n, 3) for i in range(n): ax = fig.add_subplot(gridspec[i, :]) ax.bar(df_1.Date,df_1[st[i]],alpha=0.3,color=&#39;#007acc&#39;) ax.plot(df_1.Date,df_1[st[i]] , marker=&quot;o&quot;, color=&#39;#007acc&#39;) ax.xaxis.set_major_locator(mdates.WeekdayLocator()) ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax.text(0.02, 0.5,state_name[i], transform = ax.transAxes, fontsize=25) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) . .",
            "url": "https://akshithsriram.github.io/blog/2020/08/11/CovidDashboard_auto_updated.html",
            "relUrl": "/2020/08/11/CovidDashboard_auto_updated.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Covid-19 Dashboard",
            "content": "You are now in my dashboard! All the plots here are created using matplotlib (python). Use the &#39;Show Code&#39; option to take a look at the source code. . #collapse import pandas as pd import numpy as np import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl from IPython.core.display import display,HTML %matplotlib inline dft_cases = pd.read_csv(&#39;data/SnapshotCases-28-July.csv&#39;) dft_deaths = pd.read_csv(&#39;data/SnapshotDeaths-28-July.csv&#39;) # cumulative number of cases &amp; deaths from 14-Jul-20 dft_cases[&quot;dt_today&quot;] = dft_cases[&quot;28-Jul-20&quot;] dft_cases[&quot;dt_yday&quot;] = dft_cases[&quot;27-Jul-20&quot;] dft_deaths[&quot;dt_today&quot;] = dft_deaths[&quot;28-Jul-20&quot;] dft_deaths[&quot;dt_yday&quot;] = dft_deaths[&quot;27-Jul-20&quot;] dfc_cases = dft_cases.groupby(&#39;states&#39;)[&quot;dt_today&quot;].sum() dfc_deaths = dft_deaths.groupby(&#39;states&#39;)[&quot;dt_today&quot;].sum() dfp_cases = dft_cases.groupby(&#39;states&#39;)[&quot;dt_yday&quot;].sum() dfp_deaths = dft_deaths.groupby(&#39;states&#39;)[&quot;dt_yday&quot;].sum() #Creating the new dataframe df_table df_dfc_cases = pd.DataFrame(dfc_cases).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_today&quot;: &quot;Cases&quot;}) df_dfp_cases = pd.DataFrame(dfp_cases).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_yday&quot;: &quot;PCases&quot;}) df_dfc_deaths = pd.DataFrame(dfc_deaths).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_today&quot;: &quot;Deaths&quot;}) df_dfp_deaths = pd.DataFrame(dfp_deaths).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_yday&quot;: &quot;PDeaths&quot;}) df_table = pd.merge(df_dfc_cases,df_dfp_cases, how=&#39;outer&#39;) df_table = pd.merge(df_table,df_dfc_deaths, how=&#39;outer&#39;) df_table = pd.merge(df_table,df_dfp_deaths, how=&#39;outer&#39;) for c in &#39;Cases, Deaths&#39;.split(&#39;, &#39;): df_table[f&#39;{c} (+)&#39;] = (df_table[c] - df_table[f&#39;P{c}&#39;]).clip(0) df_table[&#39;Fatality Rate&#39;] = (100* df_table[&#39;Deaths&#39;]/ df_table[&#39;Cases&#39;]).round(2) # Sorting the dataframe df_table.sort_values(by = [&#39;Cases&#39;,&#39;Deaths&#39;], ascending = [False, False], inplace = True) df_table.reset_index(drop=True, inplace = True) summary = {&quot;updated&quot;:&quot;28th July, 2020&quot;, &quot;since&quot;:&quot;27th July, 2020&quot;} for col in df_table.columns: if col not in [&quot;states&quot;, &quot;Fatality Rate&quot;]: summary[col]= df_table[col].sum() update = summary[&#39;updated&#39;] cases = summary[&#39;Cases&#39;] new = summary[&#39;Cases (+)&#39;] deaths = summary[&#39;Deaths&#39;] dnew = summary[&#39;Deaths (+)&#39;] # please un-comment the print statement to look at the summary dictionary. #print(summary) # HTML output. overview = &#39;&#39;&#39; &lt;!-- ####### HTML!! #########--&gt; &lt;h1 style=&quot;color: #5e9ca0; text-align: center;&quot;&gt;India&lt;/h1&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Last update: &lt;strong&gt;{update}&lt;/strong&gt;&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed cases:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{cases} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{new}&lt;/span&gt;)&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed deaths:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{deaths} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{dnew}&lt;/span&gt;)&lt;/p&gt; &#39;&#39;&#39; html = HTML(overview.format(update=update, cases=cases,new=new,deaths=deaths,dnew=dnew)) display(html) . . India . Last update: 28th July, 2020 . Confirmed cases: . 1514800 (+49001) . Confirmed deaths: . 34121 (+770) . #collapse dt_cols = list(dft_cases.columns[1:]) dft_ct_new_cases = dft_cases.groupby(&#39;states&#39;)[dt_cols].sum().diff(axis=1).fillna(0).astype(int) dft_ct_new_cases.sort_values(by = &#39;28-Jul-20&#39;, ascending = False,inplace = True) df = dft_ct_new_cases.copy() df.loc[&#39;Total&#39;] = df.sum() df.drop([&#39;dt_today&#39;, &#39;dt_yday&#39;], axis=1, inplace = True) n = 5 ef = df.loc[&#39;Total&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax = [] fig = plt.figure(figsize = (16,20)) gs = fig.add_gridspec(n+2, 3) # gs = fig.add_gridspec(2, 3) ax1 = fig.add_subplot(gs[0, :]) ef = df.loc[&#39;Total&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax1.bar(ef.date,ef.Total,alpha=0.3,color=&#39;#007acc&#39;) ax1.plot(ef.date,ef.Total , marker=&quot;o&quot;, color=&#39;#007acc&#39;) ax1.xaxis.set_major_locator(mdates.WeekdayLocator()) ax1.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax1.text(0.02, 0.5,&#39;India daily case count&#39;, transform = ax1.transAxes, fontsize=25); ax1.spines[&#39;right&#39;].set_visible(False) ax1.spines[&#39;top&#39;].set_visible(False) ax2 = fig.add_subplot(gs[1,0]) ef = df.loc[&#39;Maharashtra&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax2.bar(ef.date, ef.Maharashtra,color = &#39;#007acc&#39;,alpha=0.5) ax2.xaxis.set_major_locator(mdates.WeekdayLocator()) ax2.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax2.set_xticks(ax2.get_xticks()[::3]) maxyval = ef.Maharashtra.max() ax2.set_ylim([0,maxyval]) ax2.text(0.05, 0.5,&#39;Maharashtra&#39;, transform = ax2.transAxes, fontsize=20); ax2.spines[&#39;right&#39;].set_visible(False) ax2.spines[&#39;top&#39;].set_visible(False) ax3 = fig.add_subplot(gs[1,1]) ef = df.loc[&#39;Tamil Nadu&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax3.bar(ef.date, ef[&#39;Tamil Nadu&#39;],color = &#39;#007acc&#39;,alpha=0.5,) ax3.xaxis.set_major_locator(mdates.WeekdayLocator()) ax3.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax3.set_xticks(ax3.get_xticks()[::3]) ax3.text(0.05, 0.5,&#39;Tamil Nadu&#39;, transform = ax3.transAxes, fontsize=20); ax3.spines[&#39;right&#39;].set_visible(False) ax3.spines[&#39;top&#39;].set_visible(False) ax4 = fig.add_subplot(gs[1,2]) ef = df.loc[&#39;Delhi&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax4.bar(ef.date, ef.Delhi,color = &#39;#007acc&#39;,alpha=0.5) ax4.set_xticks([]) ax4.xaxis.set_major_locator(mdates.WeekdayLocator()) ax4.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax4.set_xticks(ax4.get_xticks()[::3]) ax4.spines[&#39;right&#39;].set_visible(False) ax4.spines[&#39;top&#39;].set_visible(False) ax4.text(0.05, 0.5,&#39;Delhi&#39;, transform = ax4.transAxes, fontsize=20) for i in range(n): ax.append(fig.add_subplot(gs[i+2,:])) ef = df.iloc[i+3].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax[i].bar(ef.date,ef.iloc[:,-1],color = &#39;#007acc&#39;,alpha=0.3) ax[i].plot(ef.date,ef.iloc[:,-1],marker=&#39;o&#39;,color=&#39;#007acc&#39;) ax[i].text(0.02,0.5,f&#39;{ef.columns.values[-1]}&#39;,transform = ax[i].transAxes, fontsize = 20); ax[i].xaxis.set_major_locator(mdates.WeekdayLocator()) ax[i].xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax[i].set_ylim([0,7000]) ax[i].spines[&#39;right&#39;].set_visible(False) ax[i].spines[&#39;top&#39;].set_visible(False) plt.tight_layout() . . #collapse print(df_table.to_string(index=False)) . . states Cases PCases Deaths PDeaths Cases (+) Deaths (+) Fatality Rate Maharashtra 391440 383723 14164 13882 7717 282 3.62 Tamil Nadu 227688 220716 3659 3571 6972 88 1.61 Delhi 132275 131219 3881 3853 1056 28 2.93 Andhra Pradesh 110297 102349 1148 1090 7948 58 1.04 Karnataka 107001 101465 2064 1962 5536 102 1.93 Uttar Pradesh 73951 70493 1497 1456 3458 41 2.02 West Bengal 62964 60830 1449 1411 2134 38 2.30 Gujarat 57982 56874 2372 2348 1108 24 4.09 Telangana 57142 55532 480 471 1610 9 0.84 Bihar 43591 41111 269 255 2480 14 0.62 Rajasthan 38636 37564 644 633 1072 11 1.67 Assam 34846 33475 92 90 1371 2 0.26 Haryana 32876 32127 406 397 749 9 1.23 Madhya Pradesh 29217 28589 831 821 628 10 2.84 Orissa 28107 26892 189 181 1215 8 0.67 Kerala 20895 19728 68 64 1167 4 0.33 Jammu and Kashmir 18879 18390 333 321 489 12 1.76 Punjab 14378 13769 336 318 609 18 2.34 Jharkhand 9563 8803 94 90 760 4 0.98 Goa 5287 5119 36 36 168 0 0.68 Tripura 4287 4066 21 17 221 4 0.49 Pondicherry 3013 2874 47 43 139 4 1.56 Himachal Pradesh 2330 2270 13 13 60 0 0.56 Manipur 2317 2286 0 0 31 0 0.00 Nagaland 1460 1385 4 5 75 0 0.27 Arunachal Pradesh 1330 1239 3 3 91 0 0.23 Chandigarh 934 910 14 14 24 0 1.50 Meghalaya 779 738 5 5 41 0 0.64 Sikkim 592 568 1 1 24 0 0.17 Mizoram 384 361 0 0 23 0 0.00 Andaman and Nicobar Islands 359 334 1 1 25 0 0.28 Daman and Diu 0 0 0 0 0 0 NaN Lakshadweep 0 0 0 0 0 0 NaN .",
            "url": "https://akshithsriram.github.io/blog/2020/07/28/CovidDashboard.html",
            "relUrl": "/2020/07/28/CovidDashboard.html",
            "date": " • Jul 28, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://akshithsriram.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}